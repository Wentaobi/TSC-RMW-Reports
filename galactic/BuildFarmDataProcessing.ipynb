{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import glob as glob\n",
    "# Blessed build for evaluation is\n",
    "# http://build.ros2.org/job/Rci__nightly-performance_ubuntu_focal_amd64/97/artifact/ws/test_results/buildfarm_perf_tests/*.csv/*zip*/buildfarm_perf_tests.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: wildcards not supported in HTTP.\n",
      "--2020-10-19 10:24:54--  http://build.ros2.org/job/Rci__nightly-performance_ubuntu_focal_amd64/97/artifact/ws/test_results/buildfarm_perf_tests/*.csv/*zip*/buildfarm_perf_tests.zip\n",
      "Resolving build.ros2.org (build.ros2.org)... 13.52.151.147\n",
      "Connecting to build.ros2.org (build.ros2.org)|13.52.151.147|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/zip]\n",
      "Saving to: ‘buildfarm_perf_tests.zip’\n",
      "\n",
      "buildfarm_perf_test     [ <=>                ]  83.19K  --.-KB/s    in 0.08s   \n",
      "\n",
      "2020-10-19 10:24:54 (1.01 MB/s) - ‘buildfarm_perf_tests.zip’ saved [85189]\n",
      "\n",
      "Archive:  ./data/buildfarm_perf_tests.zip\n",
      "replace ./data/overhead_node_test_results_rmw_connext_cpp_async.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
     ]
    }
   ],
   "source": [
    "! wget http://build.ros2.org/job/Rci__nightly-performance_ubuntu_focal_amd64/97/artifact/ws/test_results/buildfarm_perf_tests/*.csv/*zip*/buildfarm_perf_tests.zip\n",
    "! mv buildfarm_perf_tests.zip ./data/\n",
    "! unzip ./data/buildfarm_perf_tests.zip -d ./data/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Files: 230\n",
      "Performance Files: 176\n",
      "Overhead Files: 54\n",
      "Two Process Files: 88\n",
      "Sync Files: 115\n",
      "Async Files: 115\n",
      "pub Files: 24\n",
      "sub Files: 24\n",
      "node Files: 6\n"
     ]
    }
   ],
   "source": [
    "# First let's try to figure out blocks of data\n",
    "# I.e. what are the \"sets\" of files we can process.\n",
    "out = glob.glob(\"./data/*.csv\")\n",
    "\n",
    "print(\"Total Files: {0}\".format(len(out)))    \n",
    "perf_files = [f for f in out if \"performance\" in f]\n",
    "print(\"Performance Files: {0}\".format(len(perf_files)))\n",
    "overhead_files = [f for f in out if \"overhead\" in f]\n",
    "print(\"Overhead Files: {0}\".format(len(overhead_files)))\n",
    "two_files = [f for f in out if \"two_process\" in f]\n",
    "print(\"Two Process Files: {0}\".format(len(two_files)))\n",
    "sync_files = [f for f in out if \"_sync\" in f]\n",
    "print(\"Sync Files: {0}\".format(len(sync_files)))\n",
    "async_files = [f for f in out if \"async\" in f]\n",
    "print(\"Async Files: {0}\".format(len(async_files)))\n",
    "pub_files = [f for f in out if \"_pub\" in f]\n",
    "print(\"pub Files: {0}\".format(len(pub_files)))\n",
    "sub_files = [f for f in out if \"_sub\" in f]\n",
    "print(\"sub Files: {0}\".format(len(sub_files)))\n",
    "node_files = [f for f in out if \"node\" in f]\n",
    "print(\"node Files: {0}\".format(len(node_files)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_cols = ['mean virtual memory (Mb)',\n",
    "             'median virtual memory (Mb)',\n",
    "             'virtual memory (Mb)',\n",
    "             'mean cpu_usage (%)',\n",
    "             'median cpu_usage (%)',\n",
    "             'cpu_usage (%)',\n",
    "             'mean physical memory (Mb)',\n",
    "             'median physical memory (Mb)',\n",
    "             'physical memory (Mb)',\n",
    "             'mean resident anonymous memory (Mb)',\n",
    "             'median resident anonymous memory (Mb)',\n",
    "             'resident anonymous memory (Mb)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/overhead_node_test_results_rmw_connext_cpp_async.csv\n",
      "./data/overhead_node_test_results_rmw_cyclonedds_cpp_sync.csv\n",
      "./data/overhead_node_test_results_rmw_fastrtps_dynamic_cpp_async.csv\n",
      "./data/overhead_node_test_results_rmw_fastrtps_cpp_sync.csv\n",
      "./data/overhead_node_test_results_rmw_fastrtps_dynamic_cpp_sync.csv\n",
      "./data/overhead_node_test_results_rmw_fastrtps_cpp_async.csv\n",
      "6\n",
      "0    ./data/overhead_node_test_results_rmw_connext_...\n",
      "0    ./data/overhead_node_test_results_rmw_cycloned...\n",
      "0    ./data/overhead_node_test_results_rmw_fastrtps...\n",
      "0    ./data/overhead_node_test_results_rmw_fastrtps...\n",
      "0    ./data/overhead_node_test_results_rmw_fastrtps...\n",
      "0    ./data/overhead_node_test_results_rmw_fastrtps...\n",
      "Name: file_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Take all of the \"overhead\" files and try to merge them into a single table. \n",
    "for p in node_files:\n",
    "    print(p)\n",
    "\n",
    "df = pd.read_csv(node_files[0])\n",
    "df.columns = perf_cols\n",
    "for p in node_files[1:]:\n",
    "    temp = pd.read_csv(p)\n",
    "    temp.columns = perf_cols\n",
    "    df = df.append(temp)\n",
    "# parse the filenames and add that data. \n",
    "df[\"config\"] = [\"_\".join(n.strip('./data/overhead_node_test_results_rmw_').strip('.csv').split('_')[1:]) for n in node_files]\n",
    "df[\"vendor\"] = [n.strip('./data/overhead_node_test_results_rmw_').split('_')[0] for n in node_files]\n",
    "df = df[df.columns[::-1]]\n",
    "df[\"file_name\"] = node_files\n",
    "df.to_csv(\"node_perf.csv\")\n",
    "print(len(df))\n",
    "print(df[\"file_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fname_to_data(fname, head=\"./data/overhead_test_results_rmw_\",tail=\"_ROS2_pub.csv\"):\n",
    "    \"\"\"\n",
    "    Munge a file name into metadata. Pull out the first and seond RMW \n",
    "    along with the \"flavor\" information\n",
    "    \"\"\"\n",
    "    fname = fname.replace(head,\"\").replace(tail,\"\")\n",
    "    parts = fname.split(\"_rmw_\")\n",
    "    first = parts[0].split(\"_\")\n",
    "    second = parts[1].split(\"_\")\n",
    "    # format is rmw _ <name> _ <config> _ rwm _ <name2> _ <config2>\n",
    "    ret_val = {}\n",
    "    ret_val[\"first_rmw\"] = first[0]\n",
    "    ret_val[\"second_rmw\"] = second[0]\n",
    "    ret_val[\"first_flavor\"] = \" \".join(first[1:])\n",
    "    ret_val[\"second_flavor\"] = \" \".join(second[1:])\n",
    "    return(ret_val)\n",
    "\n",
    "fname_to_data(\"./data/overhead_test_results_rmw_fastrtps_cpp_async_rmw_connext_cpp_ROS2_pub.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pub_sub_cols = ['mean virtual memory (Mb)',\n",
    "                'median virtual memory (Mb)',\n",
    "                'virtual memory (Mb)',\n",
    "                'mean cpu_usage (%)',\n",
    "                'median cpu_usage (%)',\n",
    "                'cpu_usage (%)',\n",
    "                'mean physical memory (Mb)',\n",
    "                'median physical memory (Mb)',\n",
    "                'physical memory (Mb)',\n",
    "                'mean resident anonymous memory (Mb)',\n",
    "                'median resident anonymous memory (Mb)',\n",
    "                'resident anonymous memory (Mb)',\n",
    "                'mean latency_mean (ms)',\n",
    "                'median latency_mean (ms)',\n",
    "                'Top 5% latency (ms)',\n",
    "                'max ru_maxrss',\n",
    "                'mean received',\n",
    "                'mean sent',\n",
    "                'sum lost',\n",
    "                'mean system_cpu_usage (%)',\n",
    "                'mean system virtual memory (Mb)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out data for the pub files and repeat for sub files. \n",
    "pub_df = pd.read_csv(pub_files[0])\n",
    "print(pub_files[0])\n",
    "\n",
    "print(\"DF Cols {0} vs known cols {1}\".format(len(pub_df.columns),len(pub_sub_cols)))    \n",
    "# squish all the files into one table\n",
    "pub_df.columns = pub_sub_cols\n",
    "for p in pub_files[1:]:\n",
    "    temp = pd.read_csv(p)\n",
    "    temp.columns = pub_sub_cols\n",
    "    pub_df = pub_df.append(temp)\n",
    "# parse the file names into data and add them back to table. \n",
    "flavors = [fname_to_data(flavor) for flavor in pub_files]\n",
    "pub_df[\"from_rmw\"]= [flavor[\"first_rmw\"] for flavor in flavors]\n",
    "pub_df[\"from_rmw_flavor\"]= [flavor[\"first_flavor\"] for flavor in flavors]\n",
    "pub_df[\"to_rmw\"]= [flavor[\"second_rmw\"] for flavor in flavors]\n",
    "pub_df[\"to_rmw_flavor\"]= [flavor[\"second_flavor\"] for flavor in flavors]\n",
    "pub_df[\"file_name\"] = pub_files\n",
    "pub_df = pub_df[pub_df.columns[::-1]]\n",
    "pub_df.to_csv(\"pub_perf.csv\")\n",
    "pub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now repeat for subscribersub_perf.head()\n",
    "sub_df = pd.read_csv(sub_files[0])\n",
    "print(sub_files[0])\n",
    "\n",
    "print(\"DF Cols {0} vs known cols {1}\".format(len(sub_df.columns),len(pub_sub_cols)))    \n",
    "\n",
    "sub_df.columns = pub_sub_cols\n",
    "for p in sub_files[1:]:\n",
    "    temp = pd.read_csv(p)\n",
    "    temp.columns = pub_sub_cols\n",
    "    sub_df = sub_df.append(temp)\n",
    "    \n",
    "flavors = [fname_to_data(flavor,tail=\"_ROS2_sub.csv\") for flavor in sub_files]\n",
    "sub_df[\"from_rmw\"]= [flavor[\"first_rmw\"] for flavor in flavors]\n",
    "sub_df[\"from_rmw_flavor\"]= [flavor[\"first_flavor\"] for flavor in flavors]\n",
    "sub_df[\"to_rmw\"]= [flavor[\"second_rmw\"] for flavor in flavors]\n",
    "sub_df[\"to_rmw_flavor\"]= [flavor[\"second_flavor\"] for flavor in flavors]\n",
    "sub_df[\"file_name\"] = sub_files\n",
    "sub_df = sub_df[sub_df.columns[::-1]]\n",
    "sub_df.to_csv(\"sub_perf.csv\")\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now aggregate the performance results, there are two types two process and and \"results\"\n",
    "two_process_perf = [p for p in perf_files if \"two_process\" in p]\n",
    "result_perf_file = [p for p in perf_files if \"two_process\" not in p]\n",
    "print(\"{0} two process files and {1} results files. {2} total files.\".format(len(two_process_perf),len(result_perf_file),len(perf_files)))\n",
    "\n",
    "# From: https://github.com/ahcorde/buildfarm_perf_tests/blob/master/test/test_performance.py.in#L48\n",
    "perf_col_names = [\n",
    "    'mean latency_mean (ms)',\n",
    "    'median latency_mean (ms)',\n",
    "    '95th Percentile Latency',\n",
    "    'max ru_maxrss',\n",
    "    'mean received',\n",
    "    'mean sent',\n",
    "    'sum lost',\n",
    "    'mean cpu_usage (%)',\n",
    "    '95th Percentile CPU',\n",
    "    'median cpu_usage (%)',\n",
    "    'mean data_received (Mb)',\n",
    "    'median data_received (Mb)',\n",
    "    '95th Percentile Data Received (Mb)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fname_to_rmw_and_data(fname):\n",
    "    \"\"\"\n",
    "    Parse and return file names of the format\n",
    "    performnace_test_resuts_<optional rmw>_<rmw_name>_<rmw_flavor>_<datatype>.csv\n",
    "    E.g. \n",
    "    ./data/performance_test_results_rmw_fastrtps_dynamic_cpp_async_Array32k.csv\n",
    "    ./data/performance_test_results_FastRTPS_sync_Array2m.csv\n",
    "    ./data/performance_test_results_CycloneDDS_sync_Array1k.csv\n",
    "    \"\"\"\n",
    "    fname = fname.replace(\"./data/performance_test_two_process_results_rmw_\",\"\")\n",
    "    fname = fname.replace(\"./data/performance_test_two_process_results_\",\"\")\n",
    "    fname = fname.replace(\"./data/performance_test_results_\",\"\")\n",
    "    \n",
    "    fname = fname.replace(\".csv\",\"\")\n",
    "    parts = fname.split(\"_\");\n",
    "    ret_val = {}\n",
    "    ret_val[\"type\"] = parts[-1] # last entry is type, easy\n",
    "    if(parts[0] == \"rmw\"):\n",
    "        parts = parts[1:] # drop the first value if it is RMW\n",
    "    ret_val[\"vendor\"] = parts[0].lower() # both upper and lower is present\n",
    "    ret_val[\"flavor\"] = \"_\".join(parts[1:-1])\n",
    "    return ret_val "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_df = pd.read_csv(result_perf_file[0])\n",
    "print(result_perf_file[0])\n",
    "\n",
    "print(\"DF Cols {0} vs known cols {1}\".format(len(perf_df.columns),len(perf_col_names)))\n",
    "\n",
    "perf_df.columns = perf_col_names\n",
    "\n",
    "# smush main csv files together\n",
    "for p in result_perf_file[1:]:\n",
    "    temp = pd.read_csv(p)\n",
    "    temp.columns = perf_col_names\n",
    "    perf_df = perf_df.append(temp)\n",
    "# parse file names \n",
    "fname_data = [fname_to_rmw_and_data(p) for p in result_perf_file]\n",
    "perf_df[\"vendor\"] = [p[\"vendor\"] for p in fname_data]\n",
    "perf_df[\"flavor\"] = [p[\"flavor\"] for p in fname_data]\n",
    "perf_df[\"data_type\"] = [p[\"type\"] for p in fname_data]\n",
    "perf_df[\"file_name\"] = result_perf_file\n",
    "perf_df = perf_df[perf_df.columns[::-1]]\n",
    "perf_df.to_csv(\"perf_network_results.csv\")\n",
    "perf_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twop_df = pd.read_csv(two_process_perf[0])\n",
    "print(two_process_perf[0])\n",
    "\n",
    "print(\"DF Cols {0} vs known cols {1}\".format(len(twop_df.columns),len(perf_col_names)))\n",
    "\n",
    "twop_df.columns = perf_col_names\n",
    "\n",
    "# smush main csv files together\n",
    "for p in two_process_perf[1:]:\n",
    "    temp = pd.read_csv(p)\n",
    "    temp.columns = perf_col_names\n",
    "    twop_df = twop_df.append(temp)\n",
    "# parse file names \n",
    "fname_data = [fname_to_rmw_and_data(p) for p in two_process_perf]\n",
    "twop_df[\"vendor\"] = [p[\"vendor\"] for p in fname_data]\n",
    "twop_df[\"flavor\"] = [p[\"flavor\"] for p in fname_data]\n",
    "twop_df[\"data_type\"] = [p[\"type\"] for p in fname_data]\n",
    "twop_df[\"file_name\"] = two_process_perf\n",
    "twop_df = twop_df[twop_df.columns[::-1]]\n",
    "twop_df.to_csv(\"two_process_perf_network_results.csv\")\n",
    "twop_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(pub_files)+len(sub_files)+len(node_files)+len(two_process_perf)+len(result_perf_file)\n",
    "print(\"processed {0} of {1}\".format(total,len(glob.glob(\"./data/*.csv\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
